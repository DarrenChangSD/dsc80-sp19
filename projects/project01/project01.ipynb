{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Project 01\n",
    "\n",
    "### Due Date: Thursday, April 18, 11:59:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Instructions\n",
    "\n",
    "This Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems.  \n",
    "* Like the lab, your coding work will be developed in the accompanying `project01.py` file, that will be imported into the current notebook. This code will be autograded.\n",
    "* The project also has free response questions. To answer the free response questions, edit the markdown cell where specified (as in DSC 10). Submission of the project include uploading a pdf of this notebook to gradescope for manual grading.\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Do not change the free response cells outside the horizontal lines**\n",
    "- The format of the cells will be used in grading the free response questions.\n",
    "\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the HW! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `project01.py` (much like we do in the notebook).\n",
    "- Always document your code!\n",
    "\n",
    "**Tips for writing the free response questions**:\n",
    "- You should treat the notebook as a final report for the assignment, containing conclusions and answers to open ended questions that are graded.\n",
    "- Upon submitting the notebook, there should not be extraneous code in the notebook (e.g. any debugging code). You should only have your answers the the questions, and the necessary code and corresponding output data that serves as evidence for your responses.\n",
    "- Generally, the free response questions will involve you *using* the functions defined in your `.py` file to justify portions of your argument.\n",
    "- They should not be long, verbose answers! Typically a short paragraph will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project01 as proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The other side of Gradescope\n",
    "\n",
    "The file contains the grade-book from a fictional data science course with 535 students. \n",
    "\n",
    "**Note: this dataset is synthetically generated; it does not contain real student grades.**\n",
    "\n",
    "In this project, you will:\n",
    "1. clean and process the data to compute total course grades according to the fictional syllabus (below),\n",
    "2. qualitatively understand how students did in the course,\n",
    "3. create a curve and assess its effect.\n",
    "\n",
    "---\n",
    "\n",
    "The course syllabus is as follows:\n",
    "\n",
    "* The course consists of HW assignments, projects, 1 midterm, and a final exam.\n",
    "* The weight of the course components are HW (20%), projects (30%), midterm (20%), final (30%).\n",
    "* For the HW assignments, students can revise an assignment for one week after submission for a 10% penalty, for two weeks after submission for a 20% penalty, and beyond that for a 50% penalty. Such revisions are reflected in the `Lateness` columns in the gradebook.\n",
    "* The lowest HW assignment is dropped.\n",
    "* Students can earn extra-credit through the `extra-credit` assignment, as well as turning in project checkpoints. All of the extra-credit should amount to the equivalent of *one HW assignment*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on generalization\n",
    "\n",
    "You may assume that your code will only need to work on a gradebook for a class with the syllabus given above. That is, you may assume that the dataframe `grades` looks like the given on (in `data/grades.csv`), but \n",
    "1. may have more/fewer HW and projects,\n",
    "2. may have more/fewer students.\n",
    "\n",
    "You may assume the course components and the naming conventions are as given in the data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_fp = os.path.join('data', 'grades.csv')\n",
    "grades = pd.read_csv(grades_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing homework grades\n",
    "\n",
    "First, you will clean and process the HW grades. To do this, you will develop functions that normalize the grades, adjust for lateness, drops the lowest grade, and totals the HW grades for each student.\n",
    "\n",
    "*Note:* You should adapt the questions in this section to process the project assignments as well, as you will need to compute the project grades for a later question. The two are similar (but not identical).\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "Create a function `normalize_hw` that takes in a dataframe like `grades` and outputs a dataframe of normalized HW grades (see doctest for the format of the output). The output should **not** take the late penalty into account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Unfortunately, Gradescope sometimes experiences a delay in registering when an assignment is submitted during \"periods of heavy usage\" (i.e. near a submission deadline). You need to assess when a student's assignment was actually turned in on time, even if Gradescope did not process it in time. To do this, it is helpful to know:\n",
    "* Every late submission has to be submitted by a TA (late submissions are turned off).\n",
    "* TAs never submitted a late assignment \"just after\" the deadline. \n",
    "* The deadlines were at midnight and students had to come to staff hours to late-submit their assignment.\n",
    "\n",
    "Create a function `last_minute_submissions` that takes in the dataframe `grades` and outputs the number of submissions that were turned in on time by the student and marked 'late' by Gradescope (for each homework assignment). See the doctest for more details.\n",
    "\n",
    "*Note:* You have to figure out what's truly a late submission by looking at the data and understanding the facts about the data generating process above. There is some ambiguity in finding which submissions are truly late; your answer will be specific to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Now you need to adjust the HW grades for late submissions. Create a function `adjust_lateness` that takes in the dataframe `grades` and returns a dataframe of HW grades adjusted for lateness according to the syllabus. Only *truly* late submissions should be counted as late (as in question 2). The adjusted HW grades should be proportions between 0 and 1.\n",
    "\n",
    "*Note:* You should use your work from question 1 here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Create a function `hw_total` that takes in a dataframe of lateness-adjusted HW grades, and computes the total HW grade for each student according to the syllabus. All homework assignments should be equally weighte. Your answer should be a proportion between 0 and 1. (Don't forget to drop the lowest score!)\n",
    "\n",
    "*Note*: Don't forget to properly handle students who didn't turn in assignments! (Use your experience and common sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5** \n",
    "\n",
    "Now, you want to understand the effect that \"missing assignments\" have on the HW grade distribution.\n",
    "\n",
    "* Create a function `average_student` that takes in a dataframe like `grades` and outputs the overall HW grade of a student who hypothetically received the average grade on each HW assignment. When computing the 'average of each assignment' you *shouldn't* include people who didn't turn in the assignment.\n",
    "\n",
    "* Is this value lower or higher than the average total HW grades given by the function `hw_total`? Write your answer in the function `higher_or_lower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing extra-credit grades\n",
    "\n",
    "**Question 6**\n",
    "\n",
    "Compute the extra credit grades. To do this, you need to identify which assignments are extra-credit, total them up, *then* normalize them (the extra-credit assignments should *not* all have equal weight). To find the extra-credit assignments **read the syllabus**.\n",
    "\n",
    "Create a function `extra_credit_total` that takes in a dataframe like `grades` and returns the total extra-credit grade as a proportion between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it together\n",
    "\n",
    "**Question 7**\n",
    "\n",
    "Finally, you need to create the final course grades. To do this, you will add up the total of each course component according to the weights given in the syllabus. \n",
    "\n",
    "* Create a function `total_points` that takes in `grades` and returns the final course grades according to the syllabus. Course grades should be proportions between zero and one.\n",
    "* Create a function `final_grades` that takes in the final course grades as above and returns a Series of letter grades given by the standard cutoffs (`A >= .90`, `.90 > B >= .80`, `.80 > C >= .70`, `.70 > D >= .60`, `.60 > F`). You should not use rounding to determining the letter grades.\n",
    "* Create a function `letter_proportions` which takes in the dataframe `grades` and outputs a Series that contains the proportion of the class that received each grade. (This question requires you to put everything together).\n",
    "\n",
    "*Note*: You can and should use your functions from previous questions in this problem!\n",
    "\n",
    "*Note*: You need to create a helper function that is an analogue to question 1 for the projects. Be aware that projects may consist of both autograded (final) and free-response portions. The checkpoints are part of the extra-credit.\n",
    "\n",
    "Verify for yourself the course grade distribution and relevant statistics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Sophomores get better grades?\n",
    "\n",
    "**Question 8**\n",
    "\n",
    "You notice that students who are sophomores on average did better in the class (if you can't verify this, you should go back and check your work!). Is this difference significant, or just due to noise?\n",
    "\n",
    "Perform a hypothesis test, assessing likelihood of the null hypothesis: \n",
    "> \"sophomores earn grades that are roughly equal on average to the rest of the class.\"\n",
    "\n",
    "\n",
    "Create a function `simulate_pval` which takes in the number of simulations `N` and `grades` and returns the the likelihood that the grade of juniors was no better on average than the class as a whole (i.e. calculate the p-value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a curve\n",
    "\n",
    "You realize that certain assignments in the course were harder than other assignments and you would like take this into account. You feel if someone did very well on a difficult assignment, that it should have more effect that doing well on an easy one. You decide to try out a curve as follows:\n",
    "\n",
    "1. Convert *every* assignment to [Standard Units](https://www.inferentialthinking.com/chapters/14/2/Variability.html#standard-units).\n",
    "2. Calculate the proportion of the course grade that every assignment represents.\n",
    "3. Calculate the weighted sum of the standardized assignment scores and their weights.\n",
    "4. Now that you have a sorted list of total scores, assign the same number of each letter grade as in the un-curved distribution (this allows for an entire class to get `A`s for example, if the class is easy).\n",
    "\n",
    "**Question 9**\n",
    "\n",
    "Create a function `get_assignment_proportions` that takes in `grades` and returns a dictionary \n",
    "* keyed by assignment name \n",
    "* with values given by the proportion of the final grade that assignment makes up. \n",
    "\n",
    "*Note*: Every column in `grades` that represents a student score should be a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10**\n",
    "\n",
    "Create a function `curved_total_points` which takes in `grades` and outputs the curved total scores for each student. For the HW questions, grade adjustments should *still* be made for late-submissions, however, for simplicity, **do not** drop the lowest HW assignment. \n",
    "\n",
    "*Note*: When standardizing scores, the mean/std that you are standardizing to should *not* incorporate missing values. However, a missing assignment *should* be set to zero *before* standardizing (otherwise, you could do average by skipping all work!).\n",
    "\n",
    "Create a function `curved_letter_grades` which takes in:\n",
    "1. a Series of curved course grades (as above),\n",
    "2. a Series of letter grade distributions (e.g. the output of `letter_proportions`)\n",
    "\n",
    "and returns a Series containing the letter grade of each student according to the curve.    \n",
    "\n",
    "*Note:* You may find the `np.percentile` function useful here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the curve\n",
    "\n",
    "**Question 11**\n",
    "\n",
    "Do data analysis to understand the effect the curve has on students' grades in the given course. Write a summary of your analysis in the free response section below. You should address:\n",
    "1.  Was there a change in the median letter grade in the course between the not-curved/curved grades?\n",
    "2. How many students saw a grade increase due to the curve? Why did their grades increase?\n",
    "3. How many students saw a grade decrease due to the curve? Why did their grades decrease?\n",
    "4. Describe a hypothetical class where a student's grade might decrease due to implementing such a curve.\n",
    "5. Discuss the advantages and disadvantages of using the curve over grading on a straight-scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Free Response Cell**\n",
    "\n",
    "---\n",
    "\n",
    "**Response to Question 10 here**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations, you finished the project!\n",
    "\n",
    "### Before you submit:\n",
    "* Be sure you run the doctests on all your code in project01.py\n",
    "* Be sure your free repsonse questions are all answered, readable, and that you haven't changed the cells outside the horizontal lines!\n",
    "\n",
    "### To submit:\n",
    "* **Convert the notebook to PDF and upload to gradescope for grading the free response.**\n",
    "* **Upload the .py file to gradescope**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
